{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a5d291",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import regex as re \n",
    "import string\n",
    "import nltk\n",
    "import datetime\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_eng = stopwords.words(\"english\")\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "\n",
    "!pip install autocorrect\n",
    "from autocorrect import Speller\n",
    "spell = Speller()\n",
    "\n",
    "# import tqdm for progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922db8ed",
   "metadata": {},
   "source": [
    "## Import csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bbbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "altcoin_df = pd.read_csv(\"altcoin.csv\") \n",
    "appl_df = pd.read_csv(\"APPL.csv\") \n",
    "bitcoin_df = pd.read_csv(\"bitcoin.csv\") \n",
    "coindesk_df = pd.read_csv(\"coindesk.csv\") \n",
    "crypto_df = pd.read_csv(\"Cryptocurrency.csv\") \n",
    "gold_df = pd.read_csv(\"Gold.csv\") \n",
    "goog_df = pd.read_csv(\"GOOG.csv\") \n",
    "yhoo_df = pd.read_csv(\"YHOO.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee1552",
   "metadata": {},
   "source": [
    "### Check first few rows and shape of each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "altcoin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268afbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "altcoin_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5007f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "appl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0127da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coindesk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6689a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coindesk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d144940",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ace79",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ccd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a908b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhoo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923df9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhoo_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38c0d3",
   "metadata": {},
   "source": [
    "#### Here, it can be noticed that all dataframes have same features, so we can move forward to concatinating the data in axis=0 (row-wise) and we can further perform the EDA in the merged dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2251e84",
   "metadata": {},
   "source": [
    "### Concat Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df = pd.concat([altcoin_df, appl_df, bitcoin_df, coindesk_df, crypto_df,\n",
    "                     gold_df, goog_df, yhoo_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27791a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78781a41",
   "metadata": {},
   "source": [
    "# Saving DataFrame in CSV File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc0dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.to_csv('trade_df.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c4781",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd089800",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e814a96",
   "metadata": {},
   "source": [
    "#### Get information of the dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a483e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ab7da",
   "metadata": {},
   "source": [
    "**Datetime column is of type object, so we need to convert that into datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df['Datetime'] = trade_df['Datetime'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df['Tweet Id'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee57494",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df[trade_df['Tweet Id']==1634342993812414464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5358f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df[trade_df['Tweet Id']==1634342993812414464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a04b0d",
   "metadata": {},
   "source": [
    "# setting max_colwidth to None to see all the strings of longer length on a single line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320cc066",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c06ce8",
   "metadata": {},
   "source": [
    "# Dropping URL Column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61292223",
   "metadata": {},
   "source": [
    "We are looking at URL and User column. Since , URL doesnot have any specific information stored in it other than tweet id and username which we already have in two other columns , we are dropping the URL column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55003a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.drop(columns=['URL'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf231e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a39078",
   "metadata": {},
   "source": [
    "# Getting only username from User column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d34a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_username(user_link):\n",
    "    get_username=re.sub(r'http[s]?://twitter.com/','',user_link)\n",
    "    return get_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df['User']=trade_df['User'].apply(get_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc714165",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df['User'].value_counts().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109afe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df['Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af233f",
   "metadata": {},
   "source": [
    "# Pre-Processing Text Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(text):\n",
    "    #convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57912661",
   "metadata": {},
   "source": [
    "# Remove hashtags and words followed by punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cd2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'(\\$[A-z]+)', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb51c50",
   "metadata": {},
   "source": [
    "# Remove Multiple Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(org_text):\n",
    "    # remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', org_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7525f33",
   "metadata": {},
   "source": [
    "# Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65452a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove punctuation\n",
    "def remove_punctuation(text): \n",
    "    return text.translate(str.maketrans('','', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd3a1f",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc04331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "def remove_stop_words(tokens):\n",
    "    return [t for t in tokens if t not in stopwords_eng]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815f918",
   "metadata": {},
   "source": [
    "# Remove Urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29839dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(desc): \n",
    "    return re.sub(r'http[s]?://t.co/', '', desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6e6b7",
   "metadata": {},
   "source": [
    "# Remove Non English Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non english characters using regex\n",
    "def remove_non_eng_chrs(text): \n",
    "    return re.sub('[^a-zA-Z]', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6939d53",
   "metadata": {},
   "source": [
    "# Fix length of repeating characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175149a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fix length of characters\n",
    "def spell_len_fix(text): \n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8cb83",
   "metadata": {},
   "source": [
    "# Remove emoji's and other language characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44072d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non ascii characters like emoji and other language chars\n",
    "def remove_non_ascii_chrs(text):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0947b7",
   "metadata": {},
   "source": [
    "# Fix Spellings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to correct spelling\n",
    "def correct_spelling(tokens):\n",
    "    return [spell(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55d63d",
   "metadata": {},
   "source": [
    "# Remove new line characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03904e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_line(text):\n",
    "    text = re.sub('[\\r\\n]+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa8c42",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to tokenize\n",
    "def tokenize(text): \n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b2d51",
   "metadata": {},
   "source": [
    "# Remove Whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whitespaces\n",
    "def remove_whitespace(tokens): \n",
    "    return [t.strip() for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d805321",
   "metadata": {},
   "source": [
    "# Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb34aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lem = WordNetLemmatizer()\n",
    "# lemmaatization \n",
    "def lemmatization(tokens):\n",
    "    return [lem.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd314a",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to preprocess the text\n",
    "def preprocess_pipeline(org_text): \n",
    "  \n",
    "    \n",
    "    text = remove_urls(org_text)\n",
    "    text = to_lowercase(text)\n",
    "    text = remove_hashtags(text)\n",
    "    text = remove_spaces(text)\n",
    "    \n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_non_eng_chrs(text) \n",
    "    text = spell_len_fix(text)\n",
    "    text = remove_non_ascii_chrs(text)\n",
    "    \n",
    "    text = new_line(text)\n",
    "    tokens =nltk.word_tokenize(text)\n",
    "   # text = correct_spelling(tokens)\n",
    "    tokens = remove_whitespace(tokens)\n",
    "    tokens=remove_stop_words(tokens)\n",
    "    tokens = lemmatization(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d272b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text, using tqdm for displaying progress bar\n",
    "tqdm.pandas(desc=\"Pre-Processing Progress\")\n",
    "trade_df['preprocessed_text'] = trade_df['Text'].progress_apply(preprocess_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0823cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6788d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creating a word cloud from text\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "titles_text = ' '.join(trade_df['preprocessed_text'])\n",
    "wordcloud = WordCloud(width=800, height=500, background_color='white').generate(titles_text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Twitter Text Word Cloud')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32550101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all the hashtags from our text\n",
    "trade_df['hashtags_all'] = trade_df['Text'].str.findall(r'#\\w+')\n",
    "#counts the occurance of each hashtags \n",
    "hashtags_all=trade_df['Text'].str.findall(r'#\\w+')\n",
    "count_hashtags= hashtags_all.explode().value_counts()\n",
    "count_hashtags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56e1a9",
   "metadata": {},
   "source": [
    "# bar diagram of top 10 hashtags with its counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "sns.barplot(x=count_hashtags.index[1:11], y=count_hashtags[1:11],palette='magma')\n",
    "plt.title('Top 10 #Hashtag',fontsize=24)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Most frequent hashtags',fontsize=24)\n",
    "plt.ylabel('Count',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b524463",
   "metadata": {},
   "source": [
    "# Top 10 most active users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a380d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.set(font_scale=2)\n",
    "tweets_by_user = trade_df.groupby('User').size().sort_values(ascending=False)\n",
    "sns.barplot(x=tweets_by_user[:10], y=tweets_by_user[:10].index,palette='magma')\n",
    "plt.title('Top 10 active users by tweet volume',fontsize=24)\n",
    "plt.xlabel('Count',fontsize=24)\n",
    "plt.ylabel('Users',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68be2d8",
   "metadata": {},
   "source": [
    "# WordCloud of Users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f08416",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = ' ' .join(tweets_by_user[1:] for tweets_by_user in trade_df['User'])\n",
    "\n",
    "wordcloud_twitter = WordCloud(height=1000, width=1000,background_color=\"white\",).generate(all_users)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wordcloud_twitter, interpolation=\"bilinear\")\n",
    "plt.title('Word Cloud for Users')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db4f36",
   "metadata": {},
   "source": [
    "# Daily number of tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ea680",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6024068",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df['Datetime'] = pd.to_datetime(trade_df['Datetime'], format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df['Date'] = trade_df['Datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16346786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trade_df['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_per_day = trade_df.groupby('Date').size().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "sns.barplot(x=tweets_per_day.index, y=tweets_per_day,palette='magma')\n",
    "plt.title('Tweets per day',fontsize=24)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date',fontsize=24)\n",
    "plt.ylabel('Count',fontsize=24)\n",
    "plt.show()\n",
    "#3/100 ma k k words thyo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051df28",
   "metadata": {},
   "source": [
    "# Maximum Number of Tweets by User Per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090bc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99858ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_per_user_per_day = trade_df.groupby(['User','Date']).size().sort_values(ascending=False)\n",
    "tweets_per_user_per_day_reset= tweets_per_user_per_day.reset_index(name='Count Per Day')[:10]\n",
    "tweets_per_user_per_day_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587447c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "sns.barplot(x=tweets_per_user_per_day_reset['User'], y=tweets_per_user_per_day_reset['Count Per Day'],hue=tweets_per_user_per_day_reset['Date'],dodge=False)\n",
    "plt.title('Tweets per day per user ',fontsize=24)\n",
    "#plt.xticks(rotation=45)\n",
    "plt.xlabel('User',fontsize=24)\n",
    "plt.ylabel('Tweets per day',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e1710",
   "metadata": {},
   "source": [
    "# Frequent hashtags per day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907449c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c09259",
   "metadata": {},
   "source": [
    "We reported that numbers of tweets in date 2023-03-10 is significantly higher than any other dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_ten= trade_df[trade_df['Date']== datetime.date(2023,3,10) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ddde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_hashtags = ' ' .join([hashtags_ten[1:] for hashtags_ten in hashtags_ten['Text'].str.findall(r'#\\w+') for hashtags_ten in hashtags_ten])\n",
    "\n",
    "wordcloud_percount = WordCloud(height=800, width=1000,background_color=\"white\",).generate(daily_hashtags)\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.imshow(wordcloud_percount, interpolation=\"bilinear\")\n",
    "plt.title('Word Cloud for Date:2023-03-10 Hashtags')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"twitter_logo_unigram_hashtags.png\", format=\"png\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_nine= trade_df[trade_df['Date']== datetime.date(2023,3,8) ]\n",
    "\n",
    "daily_hashtags = ' ' .join([hashtags_nine[1:] for hashtags_nine in hashtags_nine['Text'].str.findall(r'#\\w+') for hashtags_nine in hashtags_nine])\n",
    "\n",
    "wordcloud_percount = WordCloud(height=800, width=800,background_color=\"white\",).generate(daily_hashtags)\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.imshow(wordcloud_percount, interpolation=\"bilinear\")\n",
    "plt.title('Word Cloud for Date:2023-03-09 Hashtags')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"twitter_logo_unigram_hashtags.png\", format=\"png\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b07121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_hashtags(df,title):\n",
    "#counts the occurance of each hashtags \n",
    "    hashtags_all=df['Text'].str.findall(r'#\\w+')\n",
    "    count_hashtags= hashtags_all.explode().value_counts()\n",
    "    #count_hashtags\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set(font_scale=1.5)\n",
    "\n",
    "    sns.barplot(x=count_hashtags.index[1:11], y=count_hashtags[1:11],palette='magma')\n",
    "    plt.title(f'Top 10 #Hashtag-{title}',fontsize=24)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Most frequent hashtags',fontsize=24)\n",
    "    plt.ylabel('Count',fontsize=24)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e57b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dates in trade_df['Date'].unique():\n",
    "    #date_formatting= re.sub(r'[\\-]', r',',str(dates))\n",
    "    daily_df= trade_df[trade_df['Date']== dates]\n",
    "    daily_hashtags(daily_df,dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_hashtags(df,title):\n",
    "#counts the occurance of each hashtags \n",
    "    keywords=['altcoin', 'bitcoin','coindesk','cryptocurrency','gold','appl','goog','Yhoo']\n",
    "    hashtags_all=df['Text'].str.findall(r'#\\w+')\n",
    "    \n",
    "    count_hashtags= hashtags_all.explode().value_counts()\n",
    "    \n",
    "    #count_hashtags\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.set(font_scale=1.5)\n",
    "\n",
    "    sns.barplot(x=count_hashtags.index[1:11], y=count_hashtags[1:11],palette='magma')\n",
    "    plt.title(f'Top 10 #Hashtag-{title}',fontsize=24)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Most frequent hashtags',fontsize=24)\n",
    "    plt.ylabel('Count',fontsize=24)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23955414",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dates in trade_df['Date'].unique():\n",
    "    #date_formatting= re.sub(r'[\\-]', r',',str(dates))\n",
    "    daily_df= trade_df[trade_df['Date']== dates]\n",
    "    daily_hashtags(daily_df,dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc08e7",
   "metadata": {},
   "source": [
    "# Keywords Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given keywords\n",
    "keywords = ['Altcoin', 'Bitcoin', 'Coindesk', 'Cryptocurrency', 'Gold', 'APPL', 'GOOG', 'YHOO']\n",
    "\n",
    "# DataFrame to store results\n",
    "results = pd.DataFrame(index=pd.unique(trade_df['Date']), columns=keywords)\n",
    "results.index.name = 'Date'\n",
    "\n",
    "\n",
    "user_counts = {keyword: {} for keyword in keywords}\n",
    "\n",
    "for keyword in keywords:\n",
    "    # Count tweets containing the keyword for each day\n",
    "    results[keyword] = trade_df[trade_df['Text'].str.contains(keyword, case=False, na=False)].groupby('Date').size()\n",
    "    # Count unique users mentioning the keyword for each day\n",
    "    user_counts[keyword] = trade_df[trade_df['Text'].str.contains(keyword, case=False, na=False)]['User'].nunique()\n",
    "\n",
    "# Convert user_counts to DataFrame\n",
    "user_results = pd.DataFrame.from_dict(user_counts, orient='index', columns=['Daily Users'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11931ec",
   "metadata": {},
   "source": [
    "# Daily number of tweets for each keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a112ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of daily number of tweets for each keyword\n",
    "plt.figure(figsize=(12, 6))\n",
    "for keyword in keywords:\n",
    "    plt.plot(results.index, results[keyword], label=keyword)\n",
    "plt.title('Daily Number of Tweets')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4dc95",
   "metadata": {},
   "source": [
    "# Daily Number of users for each keyword "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff265763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily number of users for each keyword\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(user_results.index, user_results['Daily Users'])\n",
    "plt.title('Daily Number of Users')\n",
    "plt.xlabel('Keyword')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee8f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
